{"componentChunkName":"component---node-modules-gatsby-theme-blog-core-src-templates-post-query-js","path":"/image-stitching/","result":{"data":{"site":{"siteMetadata":{"title":"[errorcodes@DWS ~]$","social":[{"name":"Linkedin","url":"https://github.com/dwshuo"},{"name":"Github","url":"https://github.com/dwshuo"}]}},"blogPost":{"__typename":"MdxBlogPost","id":"0c783394-e92d-55cd-b63d-fb054286c65d","excerpt":"In this blog we take look at a script I wrote which determines if images are taken of\nthe same scene, and if so stitch them together to…","body":"function _extends() { _extends = Object.assign || function (target) { for (var i = 1; i < arguments.length; i++) { var source = arguments[i]; for (var key in source) { if (Object.prototype.hasOwnProperty.call(source, key)) { target[key] = source[key]; } } } return target; }; return _extends.apply(this, arguments); }\n\nfunction _objectWithoutProperties(source, excluded) { if (source == null) return {}; var target = _objectWithoutPropertiesLoose(source, excluded); var key, i; if (Object.getOwnPropertySymbols) { var sourceSymbolKeys = Object.getOwnPropertySymbols(source); for (i = 0; i < sourceSymbolKeys.length; i++) { key = sourceSymbolKeys[i]; if (excluded.indexOf(key) >= 0) continue; if (!Object.prototype.propertyIsEnumerable.call(source, key)) continue; target[key] = source[key]; } } return target; }\n\nfunction _objectWithoutPropertiesLoose(source, excluded) { if (source == null) return {}; var target = {}; var sourceKeys = Object.keys(source); var key, i; for (i = 0; i < sourceKeys.length; i++) { key = sourceKeys[i]; if (excluded.indexOf(key) >= 0) continue; target[key] = source[key]; } return target; }\n\n/* @jsxRuntime classic */\n\n/* @jsx mdx */\nvar _frontmatter = {\n  \"title\": \"Image stitching (panoramic)\",\n  \"date\": \"2020-04-21\",\n  \"description\": \"Create a montage by identifying images taken of the same scene and viewpoint\"\n};\nvar layoutProps = {\n  _frontmatter: _frontmatter\n};\nvar MDXLayout = \"wrapper\";\nreturn function MDXContent(_ref) {\n  var components = _ref.components,\n      props = _objectWithoutProperties(_ref, [\"components\"]);\n\n  return mdx(MDXLayout, _extends({}, layoutProps, props, {\n    components: components,\n    mdxType: \"MDXLayout\"\n  }), mdx(\"p\", null, \"In this blog we take look at a script I wrote which determines if images are taken of\\nthe same scene, and if so stitch them together to create a nice image montage/panoramic.\"), mdx(\"h2\", {\n    \"id\": \"sift-keypoint-extraction\"\n  }, \"SIFT Keypoint extraction\"), mdx(\"p\", null, \"For keypoint extraction I decided to go with SIFT(Scale-Invariant Feature Transform).\\nI found SIFT to be the easiest to understand and a great introduction to key point\\nextraction. There are of course alternatives such as SURF, BRISK and FREAK.\"), mdx(\"h3\", {\n    \"id\": \"scale-space-extrema-detection\"\n  }, \"Scale-space extrema detection\"), mdx(\"p\", null, \"Extrema points are most likely key points, and to be scale invariant we must search\\nfor stable points across multiple scales.\"), mdx(\"p\", null, \"To do this SIFT utilizes an image pyramid, where each level(octave) is derived\\nfrom applying some function to the image below.\"), mdx(\"p\", null, \"For example the following image shows a image pyramid which applies the mean function\\nat each level\"), mdx(\"p\", null, mdx(\"span\", _extends({\n    parentName: \"p\"\n  }, {\n    \"className\": \"gatsby-resp-image-wrapper\",\n    \"style\": {\n      \"position\": \"relative\",\n      \"display\": \"block\",\n      \"marginLeft\": \"auto\",\n      \"marginRight\": \"auto\",\n      \"maxWidth\": \"527px\"\n    }\n  }), \"\\n      \", mdx(\"span\", _extends({\n    parentName: \"span\"\n  }, {\n    \"className\": \"gatsby-resp-image-background-image\",\n    \"style\": {\n      \"paddingBottom\": \"59.42028985507246%\",\n      \"position\": \"relative\",\n      \"bottom\": \"0\",\n      \"left\": \"0\",\n      \"backgroundImage\": \"url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAMCAIAAADtbgqsAAAACXBIWXMAAAsSAAALEgHS3X78AAAB1ElEQVQoz31RTU/UUBR9gf9g/B9uXADR4MKdK1a6YOm/8A8YowmgO1wqsTrGzEaNuJGMDCChlDCdfkxJ29evmYF03uvr+yhe2kRlRE/am/a+e9855150fhWkZJKT5ptzTikpWKGUqi4DTfdVFYSh38lOvjUJSkicxMPRSAgxVYv+plWyLEnM2WlV/56Ox1mWJmkaRXEYBEGI4ziKY5wkyeXmSkHw9Zf7bxbx8UaTy7LMtu2+1XfdAcBxXT/wS8aKophmroCXjnlxJsq8UqLOKCmElLLxqWpcCFQK/Wm1mEQH2vzu+vXd9WtH7SVeMkjiMLQdx7Ys4DfN/nGv5zhO3zQxxkhKwUoGhFDnHbaM9pL1Zdn8eD9PfjS3EkLSJIkwHg2H4DYMwW0K3oVUaJLnQRhwLlnJQdxv/bUwpcT5v4GqZkj+dvvz8uanB/q7RaMFzx2jdcv4cI/m0S9TVzTDK0q69+rG16doa3Wmu4K2V1B3dWbrMfI6j+A08E8GAy8C3TiCVXmeB+tyXSefTC6arc2HnSdo78XszhrqrqGd57PfnyHj/d2arqqXUpQAmA1jlFKIhFDwiM7iw/3XN3Vt/kBbgFHr2oKuzelvb09GvVqv+o/nnw/6haXO+GZBAAAAAElFTkSuQmCC')\",\n      \"backgroundSize\": \"cover\",\n      \"display\": \"block\"\n    }\n  })), \"\\n  \", mdx(\"img\", _extends({\n    parentName: \"span\"\n  }, {\n    \"className\": \"gatsby-resp-image-image\",\n    \"alt\": \"mean pyramid\",\n    \"title\": \"mean pyramid\",\n    \"src\": \"/blog/static/5831da6164047df5f5a96a8ab512dea1/44385/mean-pyramid.png\",\n    \"srcSet\": [\"/blog/static/5831da6164047df5f5a96a8ab512dea1/e4d6b/mean-pyramid.png 345w\", \"/blog/static/5831da6164047df5f5a96a8ab512dea1/44385/mean-pyramid.png 527w\"],\n    \"sizes\": \"(max-width: 527px) 100vw, 527px\",\n    \"style\": {\n      \"width\": \"100%\",\n      \"height\": \"100%\",\n      \"margin\": \"0\",\n      \"verticalAlign\": \"middle\",\n      \"position\": \"absolute\",\n      \"top\": \"0\",\n      \"left\": \"0\"\n    },\n    \"loading\": \"lazy\"\n  })), \"\\n    \")), mdx(\"p\", null, \"For SIFT at each level we apply the Difference of Gaussian kernel which is a fast\\napproximation to scale normalized Laplacian of Gaussian. After each level the\\nGaussian image is down sampled by a factor of 2 or 1/4th the orginal size. See below\\nfor illustration.\"), mdx(\"p\", null, mdx(\"span\", _extends({\n    parentName: \"p\"\n  }, {\n    \"className\": \"gatsby-resp-image-wrapper\",\n    \"style\": {\n      \"position\": \"relative\",\n      \"display\": \"block\",\n      \"marginLeft\": \"auto\",\n      \"marginRight\": \"auto\",\n      \"maxWidth\": \"450px\"\n    }\n  }), \"\\n      \", mdx(\"span\", _extends({\n    parentName: \"span\"\n  }, {\n    \"className\": \"gatsby-resp-image-background-image\",\n    \"style\": {\n      \"paddingBottom\": \"72.17391304347827%\",\n      \"position\": \"relative\",\n      \"bottom\": \"0\",\n      \"left\": \"0\",\n      \"backgroundImage\": \"url('data:image/jpeg;base64,/9j/2wBDABALDA4MChAODQ4SERATGCgaGBYWGDEjJR0oOjM9PDkzODdASFxOQERXRTc4UG1RV19iZ2hnPk1xeXBkeFxlZ2P/2wBDARESEhgVGC8aGi9jQjhCY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2P/wgARCAAOABQDASIAAhEBAxEB/8QAFwAAAwEAAAAAAAAAAAAAAAAAAAIDBf/EABQBAQAAAAAAAAAAAAAAAAAAAAD/2gAMAwEAAhADEAAAAdhpUHED/8QAGhAAAgMBAQAAAAAAAAAAAAAAAQIDESISMv/aAAgBAQABBQJzRPlTmUWWXEa8r//EABQRAQAAAAAAAAAAAAAAAAAAABD/2gAIAQMBAT8BP//EABQRAQAAAAAAAAAAAAAAAAAAABD/2gAIAQIBAT8BP//EABkQAAIDAQAAAAAAAAAAAAAAAAABEBEhMf/aAAgBAQAGPwJaPTtiHH//xAAbEAEAAgIDAAAAAAAAAAAAAAABABEhMWGRof/aAAgBAQABPyF9HmX0Tm4aOyLT9jIXuKItz//aAAwDAQACAAMAAAAQUA//xAAUEQEAAAAAAAAAAAAAAAAAAAAQ/9oACAEDAQE/ED//xAAVEQEBAAAAAAAAAAAAAAAAAAABEP/aAAgBAgEBPxAn/8QAGRABAQEBAQEAAAAAAAAAAAAAAREAIUFR/9oACAEBAAE/EJP9J3pmHGziiZnlBEWLgJnH1iSBAXGVVWhv/9k=')\",\n      \"backgroundSize\": \"cover\",\n      \"display\": \"block\"\n    }\n  })), \"\\n  \", mdx(\"img\", _extends({\n    parentName: \"span\"\n  }, {\n    \"className\": \"gatsby-resp-image-image\",\n    \"alt\": \"sift DOG\",\n    \"title\": \"sift DOG\",\n    \"src\": \"/blog/static/c5f5b679e0f21418e9e89e06bd3eb6e6/20e5d/sift-dog.jpg\",\n    \"srcSet\": [\"/blog/static/c5f5b679e0f21418e9e89e06bd3eb6e6/8d48c/sift-dog.jpg 345w\", \"/blog/static/c5f5b679e0f21418e9e89e06bd3eb6e6/20e5d/sift-dog.jpg 450w\"],\n    \"sizes\": \"(max-width: 450px) 100vw, 450px\",\n    \"style\": {\n      \"width\": \"100%\",\n      \"height\": \"100%\",\n      \"margin\": \"0\",\n      \"verticalAlign\": \"middle\",\n      \"position\": \"absolute\",\n      \"top\": \"0\",\n      \"left\": \"0\"\n    },\n    \"loading\": \"lazy\"\n  })), \"\\n    \")), mdx(\"p\", null, \"Once the Difference of Gaussian image pyramid has been computed, the pyramid is\\nsearched for local extrema over scale and space. A point is local in our case when\\ncompared with its 8-connected neighbours, 9 pixels from above and 9 pixels from below.\"), mdx(\"p\", null, mdx(\"span\", _extends({\n    parentName: \"p\"\n  }, {\n    \"className\": \"gatsby-resp-image-wrapper\",\n    \"style\": {\n      \"position\": \"relative\",\n      \"display\": \"block\",\n      \"marginLeft\": \"auto\",\n      \"marginRight\": \"auto\",\n      \"maxWidth\": \"289px\"\n    }\n  }), \"\\n      \", mdx(\"span\", _extends({\n    parentName: \"span\"\n  }, {\n    \"className\": \"gatsby-resp-image-background-image\",\n    \"style\": {\n      \"paddingBottom\": \"80.96885813148789%\",\n      \"position\": \"relative\",\n      \"bottom\": \"0\",\n      \"left\": \"0\",\n      \"backgroundImage\": \"url('data:image/jpeg;base64,/9j/2wBDABALDA4MChAODQ4SERATGCgaGBYWGDEjJR0oOjM9PDkzODdASFxOQERXRTc4UG1RV19iZ2hnPk1xeXBkeFxlZ2P/2wBDARESEhgVGC8aGi9jQjhCY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2P/wgARCAAQABQDASIAAhEBAxEB/8QAGAAAAwEBAAAAAAAAAAAAAAAAAAMEAQX/xAAUAQEAAAAAAAAAAAAAAAAAAAAA/9oADAMBAAIQAxAAAAHuIfOVGh//xAAZEAACAwEAAAAAAAAAAAAAAAAAAREhIjH/2gAIAQEAAQUCLlD4lo//xAAUEQEAAAAAAAAAAAAAAAAAAAAQ/9oACAEDAQE/AT//xAAUEQEAAAAAAAAAAAAAAAAAAAAQ/9oACAECAQE/AT//xAAYEAACAwAAAAAAAAAAAAAAAAAAEAIhMv/aAAgBAQAGPwIuTwv/xAAaEAACAwEBAAAAAAAAAAAAAAAAAREhMWGB/9oACAEBAAE/IZppO+sTxYMUQ1IzHpimLP/aAAwDAQACAAMAAAAQ0w//xAAUEQEAAAAAAAAAAAAAAAAAAAAQ/9oACAEDAQE/ED//xAAUEQEAAAAAAAAAAAAAAAAAAAAQ/9oACAECAQE/ED//xAAbEAEAAgMBAQAAAAAAAAAAAAABABEhMUFRYf/aAAgBAQABPxCwCbK8MzS7wblU5V69mYBWuDsZepuQAsL8n//Z')\",\n      \"backgroundSize\": \"cover\",\n      \"display\": \"block\"\n    }\n  })), \"\\n  \", mdx(\"img\", _extends({\n    parentName: \"span\"\n  }, {\n    \"className\": \"gatsby-resp-image-image\",\n    \"alt\": \"sift local extrema\",\n    \"title\": \"sift local extrema\",\n    \"src\": \"/blog/static/c1dc6bc612b7a3ab0ffb618deeda6df8/b10a4/sift-local-extrema.jpg\",\n    \"srcSet\": [\"/blog/static/c1dc6bc612b7a3ab0ffb618deeda6df8/b10a4/sift-local-extrema.jpg 289w\"],\n    \"sizes\": \"(max-width: 289px) 100vw, 289px\",\n    \"style\": {\n      \"width\": \"100%\",\n      \"height\": \"100%\",\n      \"margin\": \"0\",\n      \"verticalAlign\": \"middle\",\n      \"position\": \"absolute\",\n      \"top\": \"0\",\n      \"left\": \"0\"\n    },\n    \"loading\": \"lazy\"\n  })), \"\\n    \")), mdx(\"h4\", {\n    \"id\": \"keypoint-localization\"\n  }, \"Keypoint localization\"), mdx(\"p\", null, \"For each keypoint candidate position, interpolation is done using the taylor expansion of\\nthe Difference of Gaussian function with the keypoint as its origin, we refer to this as D(x).\\nIf the intensity at the candidate extrema is less than the 0.03 threshold value\\nstated in the David Lowe paper, it is rejected.\"), mdx(\"p\", null, \"Difference of Gaussian often has a high response to edges. In order to increase\\nstablility, we seek to remove candidate keypoints that have poorly determined\\nlocations but high edge response. \"), mdx(\"p\", null, \"To do this a 2x2 Hessian matrix is used to compute the principal curvature of D(x).\\nThe result are two eigen values lets call them alpha and beta which are proportional\\nto the principal curvatures of D(x).\"), mdx(\"p\", null, \"Key points with poorly defined peaks in the Difference of Gaussian function have\\nlarger principal curvature across the edge than along it. Thus we can form a ratio\\nwith the alpha and beta eigen values to use as a threshold, in the paper this\\nthreshold value is defined as 10.\"), mdx(\"h4\", {\n    \"id\": \"keypoint-orientation\"\n  }, \"Keypoint orientation\"), mdx(\"p\", null, \"To achieve rotation invariance we must assign the keypoint with a orientation. We\\nfirst construct a histogram with 36 bins which covers 360 degrees around our\\nkeypoint, next we calculate the gradient magnitude and direction of the neighboring\\npixels(8-connected) and add them to the histogram.\"), mdx(\"p\", null, \"The orientations within 80% of the highest peaks are assigned to the keypoint. For each\\nadditional orientation assigned, new keypoints are created having the same position\\nand scale as the original keypoint.\"), mdx(\"h4\", {\n    \"id\": \"keypoint-descriptor\"\n  }, \"Keypoint descriptor\"), mdx(\"p\", null, \"Now that we have a set of keypoints that are both scale and orientation invariant.\\nWe need to generate unique \\u201Csignatures\\u201D for these keypoints. To produce this\\nsignature we take a 16x16 pixel block around the keypoint. This block is then equally\\ndivided into 4x4 sub-blocks and for each of these 4x4 sub-blocks a 8 bin orientation\\nhistogram is created.\"), mdx(\"p\", null, \"In total this gives us 128 values, which is represented as a vector to form the\\nunique keypoint descriptor.\"), mdx(\"p\", null, \"The following is an illustration on how keypoint descriptor works. Note that instead\\nof a 16x16 block, the image shows a zoomed in 8x8 block divided into 4x4 sub-blocks.\"), mdx(\"p\", null, mdx(\"span\", _extends({\n    parentName: \"p\"\n  }, {\n    \"className\": \"gatsby-resp-image-wrapper\",\n    \"style\": {\n      \"position\": \"relative\",\n      \"display\": \"block\",\n      \"marginLeft\": \"auto\",\n      \"marginRight\": \"auto\",\n      \"maxWidth\": \"741px\"\n    }\n  }), \"\\n      \", mdx(\"span\", _extends({\n    parentName: \"span\"\n  }, {\n    \"className\": \"gatsby-resp-image-background-image\",\n    \"style\": {\n      \"paddingBottom\": \"45.21739130434783%\",\n      \"position\": \"relative\",\n      \"bottom\": \"0\",\n      \"left\": \"0\",\n      \"backgroundImage\": \"url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAJCAIAAAC9o5sfAAAACXBIWXMAAAsSAAALEgHS3X78AAABlElEQVQoz02QW4+bMBSE+f//qPtY9ZLVNlm1KRsIYBvfgm3wDYwTEkjZpqp2dDRP55NmJglzrL34zckWoV2NfhJSmUZP/v5BwzWyUcloTlHTUYmzaaJeL8G92oDiKDCwJNMQdfxrlu4lfmDLsqyuLk6Oxjrjp4CDaGRjnC09S1LOckWaQR0lOijIvQKGfq/y2/yOLfd311MvTXvcH6x3+tajAgh6Yucu2dYoVWXWwEOLUgOh46WnW1YZO15irKqKE6ZvAw9d5/TJqXoUNng39tXAkx8Q5h6/CbiX5bbJ8rY+aLipMymdd+bp09O3z1/sPcKh8bfAo04tstfg5/jmcfJa13gQYtCgo4Wh3Kkmdq8UjnH633mN7WKPCxji2J7dCbOgPY9tkrd8g46FqlMJfskCdGRHy2dcPsh5ntfW3eSFaxmm2ls2SASgVt2aJWknt+PgBZU7Vr6wYoerZ1zUQf5b++9g7cWhsdFzT4LIHJYXq64OhFPyeOJcZDnM8zUDiDE+uI+al5kQwijljGGMKaXzsvwBzgXwAng5xZ8AAAAASUVORK5CYII=')\",\n      \"backgroundSize\": \"cover\",\n      \"display\": \"block\"\n    }\n  })), \"\\n  \", mdx(\"img\", _extends({\n    parentName: \"span\"\n  }, {\n    \"className\": \"gatsby-resp-image-image\",\n    \"alt\": \"keypoint descriptor\",\n    \"title\": \"keypoint descriptor\",\n    \"src\": \"/blog/static/f1777fc33a2c13ef52b271c9dddb373b/13e20/keypoint-desc.png\",\n    \"srcSet\": [\"/blog/static/f1777fc33a2c13ef52b271c9dddb373b/e4d6b/keypoint-desc.png 345w\", \"/blog/static/f1777fc33a2c13ef52b271c9dddb373b/1e043/keypoint-desc.png 690w\", \"/blog/static/f1777fc33a2c13ef52b271c9dddb373b/13e20/keypoint-desc.png 741w\"],\n    \"sizes\": \"(max-width: 741px) 100vw, 741px\",\n    \"style\": {\n      \"width\": \"100%\",\n      \"height\": \"100%\",\n      \"margin\": \"0\",\n      \"verticalAlign\": \"middle\",\n      \"position\": \"absolute\",\n      \"top\": \"0\",\n      \"left\": \"0\"\n    },\n    \"loading\": \"lazy\"\n  })), \"\\n    \")), mdx(\"h2\", {\n    \"id\": \"feature-matching-with-flann\"\n  }, \"Feature matching with FLANN\"), mdx(\"p\", null, \"There are two common methods for feature matching, brute force matching and FLANN.\"), mdx(\"p\", null, \"Brute force matching performs an exhaustive search and guarantees the best match,\\nbut this comes at the cost of being extremely slow.\"), mdx(\"p\", null, \"FLANN or \\u201CFast Library for Approximate Nearest Neighbors\\u201D is much faster but does\\nnot gaurntee the best match,but instead provides the approximate best match.\\nTo achive its speed FLANN stores the key points in a \", mdx(\"a\", _extends({\n    parentName: \"p\"\n  }, {\n    \"href\": \"https://en.wikipedia.org/wiki/K-d_tree\"\n  }), \"k-d tree\"), \",\\nwhich is a special cases of a binary space partitioning trees. Once all the key\\npoints are inserted into the k-d tree, k-nearest neighbors algorithm is ran with k set to 2.\"), mdx(\"p\", null, \"This returns the best match and second best match, their similarities are then\\ncompared via a ratio test. If the result is a high ratio this would suggest that the\\nbest match is not unique and maybe a part of a repeated pattern, thus we should\\ndiscard the pair. If on the other hand we obtain a pair with a ratio that falls\\nwithin our threshold this would suggest that the best match is unique.\"), mdx(\"h2\", {\n    \"id\": \"code-keypoint-matching\"\n  }, \"CODE: keypoint matching\"), mdx(\"pre\", null, mdx(\"code\", _extends({\n    parentName: \"pre\"\n  }, {\n    \"className\": \"language-python\"\n  }), \"#SIFT(read note on SIFT patent)\\nsift = cv2.xfeatures2d.SIFT_create()\\nkpt1, des1 = sift.detectAndCompute(img1,None)\\nkpt2, des2 = sift.detectAndCompute(img2,None)\\n#FLANN key point matching\\nFLANN_INDEX_KDTREE = 0\\nindex_params = dict(algorithm = FLANN_INDEX_KDTREE, trees = 5)\\nsearch_params = dict(checks = 50)\\nflann = cv2.FlannBasedMatcher(index_params, search_params)\\nmatches = flann.knnMatch(des1, des2, k =2)\\n#Finding good matches\\ngood = []\\npts1 = []\\npts2 = []\\nfor i, j in matches:\\n    if i.distance < 0.8*j.distance:\\n        good.append([i])\\n        pts2.append(kpt2[i.trainIdx].pt)\\n        pts1.append(kpt1[i.queryIdx].pt)\\n#Return image with matched keypoints highlighted\\ngood = np.array(good)\\npts1 = np.array(pts1)\\npts2 = np.array(pts2)\\nprint('Matches found: %d'%(good.shape[0]))\\nout = cv2.drawMatchesKnn(img1, kpt1, img2, kpt2, good, None, flags =2)\\ncv2.imwrite(img_out+\\\"_match_init.jpg\\\", out)\\n\")), mdx(\"h3\", {\n    \"id\": \"note-on-sift-patent\"\n  }, \"Note on SIFT patent\"), mdx(\"p\", null, \"Since OpenCV 3.4.3 SIFT and SURF algorithms have been moved behind a\\n\", mdx(\"inlineCode\", {\n    parentName: \"p\"\n  }, \"OPENCV_ENABLE_NONFRE\"), \" flag. This is due to SIFT being patented and thus cannot\\nbe legally distributed under OpenCV\\u2019s MIT license.\"), mdx(\"p\", null, \"There are two workarounds for this. One is to roll back to a version before this\\nchange was pushed out. Second solution is to compile OpenCV yourself with the\\n\", mdx(\"inlineCode\", {\n    parentName: \"p\"\n  }, \"OPENCV_ENABLE_NONFREE=1\"), \" enabled. You can read more about it here \", mdx(\"a\", _extends({\n    parentName: \"p\"\n  }, {\n    \"href\": \"https://github.com/skvark/opencv-python/issues/126\"\n  }), \"OpenCV #126\"), \".\"), mdx(\"p\", null, \"According to the \", mdx(\"a\", _extends({\n    parentName: \"p\"\n  }, {\n    \"href\": \"https://patents.google.com/patent/US6711293B1/en\"\n  }), \"SIFT patent\"), \" it\\nis set to expire on 03/06/2020. A \", mdx(\"a\", _extends({\n    parentName: \"p\"\n  }, {\n    \"href\": \"https://github.com/opencv/opencv/issues/16736\"\n  }), \"Github issue\"), \"\\nhas already been opened to move SIFT back into the main repository.\"), mdx(\"h2\", {\n    \"id\": \"fundamental-matrix\"\n  }, \"Fundamental matrix\"), mdx(\"p\", null, \"The next step in our process is to calculate the fundamental matrix and determine\\nif the images have sufficient matches to be recognized as originating fromt the same\\nscene. \"), mdx(\"p\", null, \"To understand what the fundamental matrix is and why its important, we need to take a\\nlook at epipolar geometry. \"), mdx(\"p\", null, mdx(\"span\", _extends({\n    parentName: \"p\"\n  }, {\n    \"className\": \"gatsby-resp-image-wrapper\",\n    \"style\": {\n      \"position\": \"relative\",\n      \"display\": \"block\",\n      \"marginLeft\": \"auto\",\n      \"marginRight\": \"auto\",\n      \"maxWidth\": \"431px\"\n    }\n  }), \"\\n      \", mdx(\"span\", _extends({\n    parentName: \"span\"\n  }, {\n    \"className\": \"gatsby-resp-image-background-image\",\n    \"style\": {\n      \"paddingBottom\": \"70.14492753623188%\",\n      \"position\": \"relative\",\n      \"bottom\": \"0\",\n      \"left\": \"0\",\n      \"backgroundImage\": \"url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAOCAIAAACgpqunAAAACXBIWXMAAAsSAAALEgHS3X78AAAB80lEQVQoz4WTWXOiQBDH/fD7tC952K+Rt2yllqSylV2V4VKBAILKIZcHKPegK5BtxaQsK9nth64Z6F//u6dnOq9v1jQN+CiK0jR937b+M+tcwUmSqKqKMa7rOrvI8h/43Q6Hg2Wanu8vgkDTtDiOP0txDUNQU9ewUNDvu5svBS7/If6BMtDgRap3++2rYZqnfM1Vdx/AzVucoigkQlPD6vV6w+EQGrk8wvpU2hkuyxJOeLfbtb/H4zFCSJJeeH4kyzLDMDRNQ0xVVdvt1rKsyWTSZjnCjuPM53PXdX3fo2mKIB4Gg4EgCKIogocq+v0+QRC24wRhmCaJ53mgdFaGDUwly/MRhTRFCzchMCRJSpIEi263C8PLiyKLIlXgcblbrVZwHc4wKO/3e13XNVW118eURZ4DDDVzHMeybNuht4aPVBgGYHAdzjBM1DDMma6nSWz74TKusjShKFqSZZ4XWI7DuMD7xlzkWZbOZjpJos1me4ZZBv36+WhbuufOw5U3swNJ1hi6z49YkedIsjubaLq9dlxXnyqSOHp6/EGhXlniDjTMMw+Rxy9Mdm0PV/PBC33/9P3OnHDJQkyX0lTuW4aBiNvAGS4tDmLwRptKzyN+cFS2LDs8ldHOef+nSuD8sqxttSiw7/uHqnq9eCpRFNu28xfQBgbHJCo4DwAAAABJRU5ErkJggg==')\",\n      \"backgroundSize\": \"cover\",\n      \"display\": \"block\"\n    }\n  })), \"\\n  \", mdx(\"img\", _extends({\n    parentName: \"span\"\n  }, {\n    \"className\": \"gatsby-resp-image-image\",\n    \"alt\": \"Epipolar geometry\",\n    \"title\": \"Epipolar geometry\",\n    \"src\": \"/blog/static/db10f5ac3049061dcc64ce510980ac78/9cb4e/epipolar.png\",\n    \"srcSet\": [\"/blog/static/db10f5ac3049061dcc64ce510980ac78/e4d6b/epipolar.png 345w\", \"/blog/static/db10f5ac3049061dcc64ce510980ac78/9cb4e/epipolar.png 431w\"],\n    \"sizes\": \"(max-width: 431px) 100vw, 431px\",\n    \"style\": {\n      \"width\": \"100%\",\n      \"height\": \"100%\",\n      \"margin\": \"0\",\n      \"verticalAlign\": \"middle\",\n      \"position\": \"absolute\",\n      \"top\": \"0\",\n      \"left\": \"0\"\n    },\n    \"loading\": \"lazy\"\n  })), \"\\n    \")), mdx(\"p\", null, \"The image above depicts a typical stereo vision scenario, where two optical\\nsensors(\", mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"O1\"), \" and \", mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"O2\"), \") are observing an object \", mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"P\"), \", these three points together\\nforms the epipolar plane(grey area). The projection of \", mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"P\"), \" on to each image planes\\nis represented as \", mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"p\"), \" and \", mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"p\\u2019\"), \".\"), mdx(\"p\", null, \"The orange line connecting the two image sensors is referred to as the baseline, the\\nlocations where the baseline intersects the two image planes are know as the\\nepipoles(\", mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"e\"), \" and \", mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"e\\u2019\"), \"), and the intersection of the epipolar plane and the two\\nimage planes are know as the epipolar lines(blue lines).\"), mdx(\"p\", null, \"Fundamental matrix is a 3x3 homogeneous matrix that encodes information about the\\ncamera matrices, relative translation and rotation between cameras, this allows us\\nto use epipolar geometry to deduce relations between images pairs without\\nknowing all the constraints. In other words if we know the fundamental matrix, any\\npoint in one image allows us to calculate the epipolar line of the respective\\npoint in the other image.\"), mdx(\"p\", null, \"Luckily for us, we do not acutally need to know the intrinsic and extrinsic camera\\nmatrices nor the relative transformations between the cameras to calculate the\\nfundamental matrix. We can simply estimate the fundamental matrix with\\n\", mdx(\"a\", _extends({\n    parentName: \"p\"\n  }, {\n    \"href\": \"https://en.wikipedia.org/wiki/Random_sample_consensus\"\n  }), \"Random sample consensus (RANSAC)\"), \".\"), mdx(\"h2\", {\n    \"id\": \"homography-estimation-and-image-stitching\"\n  }, \"Homography estimation and image stitching\"), mdx(\"p\", null, \"The final step in image stitching is finding the homography matrix. The homography matrix\\nin essence allows an image to be transformed from one image plane to another. \"), mdx(\"p\", null, \"To estimate the homography matrix we can again use RANSAC.\\nEstimating the homography matrix also serves a second purpose, if we see a\\nsignificant drop in the number of matches this would indicate that the images can\\nnot be aligned accurately enought to form a good panoramic.\"), mdx(\"h2\", {\n    \"id\": \"code-fundamental-and-homography-matrix\"\n  }, \"CODE: Fundamental and Homography matrix\"), mdx(\"pre\", null, mdx(\"code\", _extends({\n    parentName: \"pre\"\n  }, {\n    \"className\": \"language-python\"\n  }), \"# good: matched pairs from FLANN\\n# pts1: matched point from image 1\\n# pts2: matched point from image 2 \\n\\ndef homoEst(pts1, pts2, good):\\n    H, stat = cv2.findHomography(pts1, pts2, cv2.RANSAC, ransacReprojThreshold = 1.0, confidence = 0.99)\\n    h_match = good[stat.ravel() == 1]\\n    print(\\\"Inliers count after Homography estimate %d\\\"%(h_match.shape[0]))\\n    return H, h_match\\n\\ndef fundEst(pts1, pts2, good):\\n    FM, mask = cv2.findFundamentalMat(pts1, pts2, cv2.FM_RANSAC, 1.0, 0.99)\\n    fm_match = good[mask.ravel() == 1]\\n    print(\\\"Inliers count after Fundamental estimate: %d\\\"%(fm_match.shape[0]))\\n    return FM, fm_match\\n\")), mdx(\"h2\", {\n    \"id\": \"image-stitching\"\n  }, \"Image stitching\"), mdx(\"p\", null, \"If we retain sufficent keypoint pairs after running through Homography estimation\\nand Fundamental matrix estimation, we can then begin image stitching.\"), mdx(\"p\", null, \"First step in the process is to determine an anchor image which will remain fixed,\\nwhile the second image will be warped and mapped to the perspective of the anchor\\nimage.\"), mdx(\"p\", null, \"To do this we can calculate the norm of the homography matrix. Note that norm-2 takes\\nthe inverse of the homography matrix this is due to the original homography matrix\\nbeing calculated from image 1 mapped to image 2.\"), mdx(\"pre\", null, mdx(\"code\", _extends({\n    parentName: \"pre\"\n  }, {\n    \"className\": \"language-python\"\n  }), \"norm1 = np.sqrt(H[-1,0]**2 + H[-1,1]**2)\\nnorm2 = np.sqrt(np.linalg.inv(H)[-1,0]**2 + np.linalg.inv(H)[-1,1]**2)\\n\")), mdx(\"p\", null, \"If norm-1 is larger than norm-2 we warp image 1 to image 2, if on the other hand\\nnorm-2 is larger than norm-1 we warp image 2 to image 1.\"), mdx(\"p\", null, \"Once the anchor image has been determined we can calculate a translation matrix for\\nthe second image by using the homography matrix to remap the image corners.\"), mdx(\"pre\", null, mdx(\"code\", _extends({\n    parentName: \"pre\"\n  }, {\n    \"className\": \"language-python\"\n  }), \"#remap corners to new frame\\ndef remap(x,y,z,w,H):\\n    x_dot = np.dot(H,x)\\n    y_dot = np.dot(H,y)\\n    z_dot = np.dot(H,z)\\n    w_dot = np.dot(H,w)\\n    return x_dot/x_dot[-1], y_dot/y_dot[-1], z_dot/z_dot[-1], w_dot/w_dot[-1]\\n\\n#calculates the translation offset base on the corners\\n#returns a compsite matrix\\ndef calcTranslation(img1, img2, H):\\n    C1,C2,C3,C4 = remap(np.array([0,0,1]),np.array([img1.shape[1],img1.shape[0],1]),np.array([0,img1.shape[0],1]),np.array([img1.shape[1],0,1]),H)\\n    minX = min([C1[0],C2[0],C3[0],C4[0]])\\n    minY = min([C1[1],C2[1],C3[1],C4[1]])\\n    osX = abs(minX) if minX < 0 else  0\\n    osY = abs(minY) if minY < 0 else  0\\n    matrix = np.array([ [1,0,osX],[0,1,osY],[0,0,1] ])\\n    composite = np.dot(matrix, H)\\n    return composite, osX, osY\\n\")), mdx(\"p\", null, \"Next to integrate both images together we need to calculate the new coordinates for both image 1 and image 2.\"), mdx(\"pre\", null, mdx(\"code\", _extends({\n    parentName: \"pre\"\n  }, {\n    \"className\": \"language-python\"\n  }), \"def warp(composite, osx, osy, img1, img2):\\n    #calculate new coordinates for image1 and image 2\\n    img1_c1, img1_c2, img1_c3, img1_c4 = \\\\\\n        remap(np.array([0,0,1]),np.array([img1.shape[1],img1.shape[0],1]),np.array([0,img1.shape[0],1]),np.array([img1.shape[1],0 ,1]),composite)\\n    img2_c1 = (osx, osy)\\n    img2_c2 = (osx + img2.shape[1], osy + img2.shape[0])\\n    img2_c3 = (osx, osy + img2.shape[0])\\n    img2_c4 = (osx+img2.shape[1], osy)\\n    #calculate size of new image\\n    col = max([img1_c1[0], img1_c2[0], img1_c3[0], img1_c4[0],\\\\\\n            img2_c1[0], img2_c2[0], img2_c3[0], img2_c4[0] ]) \\n    row = max([img1_c1[1], img1_c2[1], img1_c3[1], img1_c4[1],\\\\\\n            img2_c1[1], img2_c2[1], img2_c3[1], img2_c4[1] ])\\n    #print image size\\n    r1 = cv2.warpPerspective(img1, composite, (int(col),int(row)), flags = cv2.INTER_LINEAR)\\n    r2 = np.zeros(r1.shape, dtype = r1.dtype)\\n    r2[int(osy):img2.shape[0]+int(osy), int(osx):img2.shape[1]+int(osx)] = img2\\n    return r1, r2\\n\")), mdx(\"h3\", {\n    \"id\": \"image-blending\"\n  }, \"Image blending\"), mdx(\"p\", null, \"At this step we have the final canvas size of the panoramic and two images with its\\ncoordinates remapped/wrapped. For regions that are not overlapping we can copy\\ndirectly from source image to the final canvas. For regions that are overlapping we\\ncan create a mask with its weight split 20/80.\"), mdx(\"pre\", null, mdx(\"code\", _extends({\n    parentName: \"pre\"\n  }, {\n    \"className\": \"language-python\"\n  }), \"stitch = img1_canvas + img2_canvas\\noverlap1 = np.copy(img1_canvas)\\noverlap2 = np.copy(img2_canvas)\\noverlap1[np.where(stitch ==2)] = 0.20\\noverlap2[np.where(stitch ==2)] = 0.80\\nfin_stitch = (r1*overlap1) + (r2*overlap2)\\nfin_stitch = cv2.GaussianBlur(fin_stitch, (3,3), 2)\\ncv2.imwrite(img_out, fin_stitch)\\n\")), mdx(\"h2\", {\n    \"id\": \"results\"\n  }, \"Results\"), mdx(\"p\", null, \"Below are the two images that we wish to stitch together\"), mdx(\"p\", null, mdx(\"span\", _extends({\n    parentName: \"p\"\n  }, {\n    \"className\": \"gatsby-resp-image-wrapper\",\n    \"style\": {\n      \"position\": \"relative\",\n      \"display\": \"block\",\n      \"marginLeft\": \"auto\",\n      \"marginRight\": \"auto\",\n      \"maxWidth\": \"1017px\"\n    }\n  }), \"\\n      \", mdx(\"span\", _extends({\n    parentName: \"span\"\n  }, {\n    \"className\": \"gatsby-resp-image-background-image\",\n    \"style\": {\n      \"paddingBottom\": \"40.869565217391305%\",\n      \"position\": \"relative\",\n      \"bottom\": \"0\",\n      \"left\": \"0\",\n      \"backgroundImage\": \"url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAICAIAAAB2/0i6AAAACXBIWXMAAAsSAAALEgHS3X78AAAB80lEQVQY0wHoARf+ANHY4L7EzKmts5icoGprbHFydJudor3GzdvS2dPCydXk7Nri68fO1qessJOWmZSXm6+0udLa4dzl7tDY4QDJ0Nmwt76HiY2Jioxyc3Nubm+MjpKkrbXc1dvOvcXM2uPHztersLeKjI90dnaBg4Scn6K0usDV3ubU3uUAxc3Ut77EkJOVaWlobm5th4mJh4mMsLrBz8jPybjBv8zVs7i/oaSohIaIYmNkaWprgIOEoaWqwcjPz9jgAMDJ0bvDy5qeoVxcWk5LSGVjYKWprqSss7uzucGwt7G8xZaZnoCDhYOFhW9xcVZWVX+ChIOGiaarss3V3QCgpq2ChYhTTktEQT04My5DPTdua2peX11oVlS6qK6tucCYm6BzdXVaWVhmZmVtb2+ChIZ7fYGnrrW6wsoAPjg1LCYiMi0qODMvPjgyR0A6QTo2RURBWUdHr52koKy0o6ivdXh5TExKRURDUVFPdHZ2nKGnjpKZoqiuAF5XRVpVQ1dSQlRQQ05LQF5aUFhTTE1NRVxLRZ+MlI6aoWhpa0dEQzo4Ny8sKi8rKE1LSmlqbFhYWFJSUQBVTz1QSzVPSjVRTThJRTRLSDZQTTlMTTheSThUODcvMC8qJCIrJyYvLCo0MC00MjA5NDE6NjQ8OTZAPjsnIvCxA6XqsAAAAABJRU5ErkJggg==')\",\n      \"backgroundSize\": \"cover\",\n      \"display\": \"block\"\n    }\n  })), \"\\n  \", mdx(\"img\", _extends({\n    parentName: \"span\"\n  }, {\n    \"className\": \"gatsby-resp-image-image\",\n    \"alt\": \"original images\",\n    \"title\": \"original images\",\n    \"src\": \"/blog/static/f357846c31f722084a23b86a8e3f4f44/44a54/image2-image3.png\",\n    \"srcSet\": [\"/blog/static/f357846c31f722084a23b86a8e3f4f44/e4d6b/image2-image3.png 345w\", \"/blog/static/f357846c31f722084a23b86a8e3f4f44/1e043/image2-image3.png 690w\", \"/blog/static/f357846c31f722084a23b86a8e3f4f44/44a54/image2-image3.png 1017w\"],\n    \"sizes\": \"(max-width: 1017px) 100vw, 1017px\",\n    \"style\": {\n      \"width\": \"100%\",\n      \"height\": \"100%\",\n      \"margin\": \"0\",\n      \"verticalAlign\": \"middle\",\n      \"position\": \"absolute\",\n      \"top\": \"0\",\n      \"left\": \"0\"\n    },\n    \"loading\": \"lazy\"\n  })), \"\\n    \")), mdx(\"p\", null, \"Here are the keypoints detected after the inital FLANN matching\"), mdx(\"p\", null, mdx(\"span\", _extends({\n    parentName: \"p\"\n  }, {\n    \"className\": \"gatsby-resp-image-wrapper\",\n    \"style\": {\n      \"position\": \"relative\",\n      \"display\": \"block\",\n      \"marginLeft\": \"auto\",\n      \"marginRight\": \"auto\",\n      \"maxWidth\": \"1380px\"\n    }\n  }), \"\\n      \", mdx(\"span\", _extends({\n    parentName: \"span\"\n  }, {\n    \"className\": \"gatsby-resp-image-background-image\",\n    \"style\": {\n      \"paddingBottom\": \"37.391304347826086%\",\n      \"position\": \"relative\",\n      \"bottom\": \"0\",\n      \"left\": \"0\",\n      \"backgroundImage\": \"url('data:image/jpeg;base64,/9j/2wBDABALDA4MChAODQ4SERATGCgaGBYWGDEjJR0oOjM9PDkzODdASFxOQERXRTc4UG1RV19iZ2hnPk1xeXBkeFxlZ2P/2wBDARESEhgVGC8aGi9jQjhCY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2P/wgARCAAHABQDASIAAhEBAxEB/8QAFgABAQEAAAAAAAAAAAAAAAAAAAIB/8QAFQEBAQAAAAAAAAAAAAAAAAAAAAH/2gAMAwEAAhADEAAAAZkTQv8A/8QAFxABAQEBAAAAAAAAAAAAAAAAAgEAA//aAAgBAQABBQJdYlXp3R3/xAAUEQEAAAAAAAAAAAAAAAAAAAAQ/9oACAEDAQE/AT//xAAUEQEAAAAAAAAAAAAAAAAAAAAQ/9oACAECAQE/AT//xAAWEAADAAAAAAAAAAAAAAAAAAAAECH/2gAIAQEABj8CUP/EABYQAQEBAAAAAAAAAAAAAAAAAAERAP/aAAgBAQABPyGsFTAYCTN//9oADAMBAAIAAwAAABAED//EABURAQEAAAAAAAAAAAAAAAAAAAEQ/9oACAEDAQE/EGf/xAAUEQEAAAAAAAAAAAAAAAAAAAAQ/9oACAECAQE/ED//xAAaEAACAgMAAAAAAAAAAAAAAAAAEQEhQVGR/9oACAEBAAE/ENZMlJGe6xZ73cSf/9k=')\",\n      \"backgroundSize\": \"cover\",\n      \"display\": \"block\"\n    }\n  })), \"\\n  \", mdx(\"img\", _extends({\n    parentName: \"span\"\n  }, {\n    \"className\": \"gatsby-resp-image-image\",\n    \"alt\": \"FLANN matching\",\n    \"title\": \"FLANN matching\",\n    \"src\": \"/blog/static/b98a068119427ba2f9f1ec2e1fec69ba/89b2d/image2_image3_match_init.jpg\",\n    \"srcSet\": [\"/blog/static/b98a068119427ba2f9f1ec2e1fec69ba/8d48c/image2_image3_match_init.jpg 345w\", \"/blog/static/b98a068119427ba2f9f1ec2e1fec69ba/15ec7/image2_image3_match_init.jpg 690w\", \"/blog/static/b98a068119427ba2f9f1ec2e1fec69ba/89b2d/image2_image3_match_init.jpg 1380w\", \"/blog/static/b98a068119427ba2f9f1ec2e1fec69ba/3acf0/image2_image3_match_init.jpg 2000w\"],\n    \"sizes\": \"(max-width: 1380px) 100vw, 1380px\",\n    \"style\": {\n      \"width\": \"100%\",\n      \"height\": \"100%\",\n      \"margin\": \"0\",\n      \"verticalAlign\": \"middle\",\n      \"position\": \"absolute\",\n      \"top\": \"0\",\n      \"left\": \"0\"\n    },\n    \"loading\": \"lazy\"\n  })), \"\\n    \")), mdx(\"p\", null, \"Inlier keypoints after Fundamental matrix estimation\"), mdx(\"p\", null, mdx(\"span\", _extends({\n    parentName: \"p\"\n  }, {\n    \"className\": \"gatsby-resp-image-wrapper\",\n    \"style\": {\n      \"position\": \"relative\",\n      \"display\": \"block\",\n      \"marginLeft\": \"auto\",\n      \"marginRight\": \"auto\",\n      \"maxWidth\": \"1380px\"\n    }\n  }), \"\\n      \", mdx(\"span\", _extends({\n    parentName: \"span\"\n  }, {\n    \"className\": \"gatsby-resp-image-background-image\",\n    \"style\": {\n      \"paddingBottom\": \"37.391304347826086%\",\n      \"position\": \"relative\",\n      \"bottom\": \"0\",\n      \"left\": \"0\",\n      \"backgroundImage\": \"url('data:image/jpeg;base64,/9j/2wBDABALDA4MChAODQ4SERATGCgaGBYWGDEjJR0oOjM9PDkzODdASFxOQERXRTc4UG1RV19iZ2hnPk1xeXBkeFxlZ2P/2wBDARESEhgVGC8aGi9jQjhCY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2P/wgARCAAHABQDASIAAhEBAxEB/8QAFQABAQAAAAAAAAAAAAAAAAAAAAL/xAAVAQEBAAAAAAAAAAAAAAAAAAAAAf/aAAwDAQACEAMQAAABiRKC/wD/xAAXEAEBAQEAAAAAAAAAAAAAAAACAQAD/9oACAEBAAEFAl2iVendHf/EABQRAQAAAAAAAAAAAAAAAAAAABD/2gAIAQMBAT8BP//EABQRAQAAAAAAAAAAAAAAAAAAABD/2gAIAQIBAT8BP//EABcQAAMBAAAAAAAAAAAAAAAAAAAQESH/2gAIAQEABj8CWQ//xAAYEAEBAQEBAAAAAAAAAAAAAAABABEhQf/aAAgBAQABPyHlVSPyOwYv/9oADAMBAAIAAwAAABCHz//EABQRAQAAAAAAAAAAAAAAAAAAABD/2gAIAQMBAT8QP//EABQRAQAAAAAAAAAAAAAAAAAAABD/2gAIAQIBAT8QP//EABsQAQACAgMAAAAAAAAAAAAAAAEAQREhMVGB/9oACAEBAAE/EBDRHjEBT0Z2HGxn/9k=')\",\n      \"backgroundSize\": \"cover\",\n      \"display\": \"block\"\n    }\n  })), \"\\n  \", mdx(\"img\", _extends({\n    parentName: \"span\"\n  }, {\n    \"className\": \"gatsby-resp-image-image\",\n    \"alt\": \"Fundamental matrix estimation\",\n    \"title\": \"Fundamental matrix estimation\",\n    \"src\": \"/blog/static/4903e17e851d6b8f2762c70fa3bf2f6c/89b2d/image2_image3_match_fund.jpg\",\n    \"srcSet\": [\"/blog/static/4903e17e851d6b8f2762c70fa3bf2f6c/8d48c/image2_image3_match_fund.jpg 345w\", \"/blog/static/4903e17e851d6b8f2762c70fa3bf2f6c/15ec7/image2_image3_match_fund.jpg 690w\", \"/blog/static/4903e17e851d6b8f2762c70fa3bf2f6c/89b2d/image2_image3_match_fund.jpg 1380w\", \"/blog/static/4903e17e851d6b8f2762c70fa3bf2f6c/3acf0/image2_image3_match_fund.jpg 2000w\"],\n    \"sizes\": \"(max-width: 1380px) 100vw, 1380px\",\n    \"style\": {\n      \"width\": \"100%\",\n      \"height\": \"100%\",\n      \"margin\": \"0\",\n      \"verticalAlign\": \"middle\",\n      \"position\": \"absolute\",\n      \"top\": \"0\",\n      \"left\": \"0\"\n    },\n    \"loading\": \"lazy\"\n  })), \"\\n    \")), mdx(\"p\", null, \"Remaining keypoints after homography estimation\"), mdx(\"p\", null, mdx(\"span\", _extends({\n    parentName: \"p\"\n  }, {\n    \"className\": \"gatsby-resp-image-wrapper\",\n    \"style\": {\n      \"position\": \"relative\",\n      \"display\": \"block\",\n      \"marginLeft\": \"auto\",\n      \"marginRight\": \"auto\",\n      \"maxWidth\": \"1380px\"\n    }\n  }), \"\\n      \", mdx(\"span\", _extends({\n    parentName: \"span\"\n  }, {\n    \"className\": \"gatsby-resp-image-background-image\",\n    \"style\": {\n      \"paddingBottom\": \"37.391304347826086%\",\n      \"position\": \"relative\",\n      \"bottom\": \"0\",\n      \"left\": \"0\",\n      \"backgroundImage\": \"url('data:image/jpeg;base64,/9j/2wBDABALDA4MChAODQ4SERATGCgaGBYWGDEjJR0oOjM9PDkzODdASFxOQERXRTc4UG1RV19iZ2hnPk1xeXBkeFxlZ2P/2wBDARESEhgVGC8aGi9jQjhCY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2P/wgARCAAHABQDASIAAhEBAxEB/8QAFwABAAMAAAAAAAAAAAAAAAAAAAECA//EABQBAQAAAAAAAAAAAAAAAAAAAAD/2gAMAwEAAhADEAAAAc4CwP/EABgQAAMBAQAAAAAAAAAAAAAAAAECAwAR/9oACAEBAAEFAnuC7V7hdgP/xAAUEQEAAAAAAAAAAAAAAAAAAAAQ/9oACAEDAQE/AT//xAAUEQEAAAAAAAAAAAAAAAAAAAAQ/9oACAECAQE/AT//xAAXEAADAQAAAAAAAAAAAAAAAAAAECER/9oACAEBAAY/Aoph/8QAGRABAQADAQAAAAAAAAAAAAAAAQARIUHh/9oACAEBAAE/IQSlDs3uxbRf/9oADAMBAAIAAwAAABBwD//EABQRAQAAAAAAAAAAAAAAAAAAABD/2gAIAQMBAT8QP//EABQRAQAAAAAAAAAAAAAAAAAAABD/2gAIAQIBAT8QP//EABgQAAMBAQAAAAAAAAAAAAAAAAERIQBR/9oACAEBAAE/EORiiWqCjpF5a6Og7//Z')\",\n      \"backgroundSize\": \"cover\",\n      \"display\": \"block\"\n    }\n  })), \"\\n  \", mdx(\"img\", _extends({\n    parentName: \"span\"\n  }, {\n    \"className\": \"gatsby-resp-image-image\",\n    \"alt\": \"Homography matrix\",\n    \"title\": \"Homography matrix\",\n    \"src\": \"/blog/static/67609190719917e538130c580c130ae5/89b2d/image2_image3_match_homo.jpg\",\n    \"srcSet\": [\"/blog/static/67609190719917e538130c580c130ae5/8d48c/image2_image3_match_homo.jpg 345w\", \"/blog/static/67609190719917e538130c580c130ae5/15ec7/image2_image3_match_homo.jpg 690w\", \"/blog/static/67609190719917e538130c580c130ae5/89b2d/image2_image3_match_homo.jpg 1380w\", \"/blog/static/67609190719917e538130c580c130ae5/3acf0/image2_image3_match_homo.jpg 2000w\"],\n    \"sizes\": \"(max-width: 1380px) 100vw, 1380px\",\n    \"style\": {\n      \"width\": \"100%\",\n      \"height\": \"100%\",\n      \"margin\": \"0\",\n      \"verticalAlign\": \"middle\",\n      \"position\": \"absolute\",\n      \"top\": \"0\",\n      \"left\": \"0\"\n    },\n    \"loading\": \"lazy\"\n  })), \"\\n    \")), mdx(\"p\", null, \"Finally here are the two images stitched together along with the output log\"), mdx(\"p\", null, mdx(\"span\", _extends({\n    parentName: \"p\"\n  }, {\n    \"className\": \"gatsby-resp-image-wrapper\",\n    \"style\": {\n      \"position\": \"relative\",\n      \"display\": \"block\",\n      \"marginLeft\": \"auto\",\n      \"marginRight\": \"auto\",\n      \"maxWidth\": \"1138px\"\n    }\n  }), \"\\n      \", mdx(\"span\", _extends({\n    parentName: \"span\"\n  }, {\n    \"className\": \"gatsby-resp-image-background-image\",\n    \"style\": {\n      \"paddingBottom\": \"89.56521739130436%\",\n      \"position\": \"relative\",\n      \"bottom\": \"0\",\n      \"left\": \"0\",\n      \"backgroundImage\": \"url('data:image/jpeg;base64,/9j/2wBDABALDA4MChAODQ4SERATGCgaGBYWGDEjJR0oOjM9PDkzODdASFxOQERXRTc4UG1RV19iZ2hnPk1xeXBkeFxlZ2P/2wBDARESEhgVGC8aGi9jQjhCY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2P/wgARCAASABQDASIAAhEBAxEB/8QAGAABAQEBAQAAAAAAAAAAAAAAAAQCBQH/xAAUAQEAAAAAAAAAAAAAAAAAAAAA/9oADAMBAAIQAxAAAAG2WXJ0HFHuwlB//8QAHBAAAgICAwAAAAAAAAAAAAAAAQIAAyMyBBIi/9oACAEBAAEFAu+NT6utVGF2FHInIcu6ay3b/8QAFBEBAAAAAAAAAAAAAAAAAAAAIP/aAAgBAwEBPwEf/8QAFBEBAAAAAAAAAAAAAAAAAAAAIP/aAAgBAgEBPwEf/8QAGxABAAEFAQAAAAAAAAAAAAAAAQACEBExURL/2gAIAQEABj8CHpYMGpTT5dTUF5C//8QAGxAAAgMAAwAAAAAAAAAAAAAAAREAITEQUXH/2gAIAQEAAT8h6agy+wKmiNshyARI4XZYQJGJy8PJ/9oADAMBAAIAAwAAABDgDzz/xAAUEQEAAAAAAAAAAAAAAAAAAAAg/9oACAEDAQE/EB//xAAUEQEAAAAAAAAAAAAAAAAAAAAg/9oACAECAQE/EB//xAAgEAEAAgIBBAMAAAAAAAAAAAABACERUTFBYXGRobHR/9oACAEBAAE/EEKHLKJsJhLzQJHZR3O012jWQW+KMVEvDqThxUNAI0Xb+z4E6sXq/bP/2Q==')\",\n      \"backgroundSize\": \"cover\",\n      \"display\": \"block\"\n    }\n  })), \"\\n  \", mdx(\"img\", _extends({\n    parentName: \"span\"\n  }, {\n    \"className\": \"gatsby-resp-image-image\",\n    \"alt\": \"Final image\",\n    \"title\": \"Final image\",\n    \"src\": \"/blog/static/10dfad393c04c26c2c3023d1feb2a19b/e8a7f/image2_image3.jpg\",\n    \"srcSet\": [\"/blog/static/10dfad393c04c26c2c3023d1feb2a19b/8d48c/image2_image3.jpg 345w\", \"/blog/static/10dfad393c04c26c2c3023d1feb2a19b/15ec7/image2_image3.jpg 690w\", \"/blog/static/10dfad393c04c26c2c3023d1feb2a19b/e8a7f/image2_image3.jpg 1138w\"],\n    \"sizes\": \"(max-width: 1138px) 100vw, 1138px\",\n    \"style\": {\n      \"width\": \"100%\",\n      \"height\": \"100%\",\n      \"margin\": \"0\",\n      \"verticalAlign\": \"middle\",\n      \"position\": \"absolute\",\n      \"top\": \"0\",\n      \"left\": \"0\"\n    },\n    \"loading\": \"lazy\"\n  })), \"\\n    \")), mdx(\"pre\", null, mdx(\"code\", _extends({\n    parentName: \"pre\"\n  }, {}), \"Comparing image2.JPG and image3.JPG\\nMatches found: 1287\\nInliers count after Fundamental estimate: 966\\nFundamental decision ---\\nMatched scene: inlier threshold meet\\nInliers count after Homography estimate 397\\nHomography decision ---\\nimage2_image3 Possible for alignment\\nAlignment possible: combine images\\nWarp Image 1 -> Image 2\\n\")));\n}\n;\nMDXContent.isMDXComponent = true;","slug":"/image-stitching/","title":"Image stitching (panoramic)","tags":[],"date":"April 21, 2020","image":null,"imageAlt":null,"socialImage":null},"previous":{"__typename":"MdxBlogPost","id":"18c41731-b505-5904-8eab-9695a32124dd","excerpt":"Ordinarily when a image is resized each pixel is treated equally, meaning everthing gets\nreduced or increased by the same amount. This leads…","slug":"/seam-carving/","title":"Content aware image resizing (seam carving)","date":"September 17, 2019"},"next":null},"pageContext":{"id":"0c783394-e92d-55cd-b63d-fb054286c65d","previousId":"18c41731-b505-5904-8eab-9695a32124dd","maxWidth":1380}},"staticQueryHashes":["2744905544","3090755652","386998304","764694655"]}